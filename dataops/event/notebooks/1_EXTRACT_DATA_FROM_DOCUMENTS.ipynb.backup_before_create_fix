{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "cd4od6afsmfioaht4pm5",
   "authorId": "7518827724888",
   "authorName": "USER",
   "authorEmail": "",
   "sessionId": "4d595c03-e294-41fb-a6fe-5fa0fc512669",
   "lastEditTime": 1761781358085
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9ba374-cd85-415e-b3e5-a9e862c9d395",
   "metadata": {
    "collapsed": false,
    "name": "title",
    "resultHeight": 74
   },
   "source": [
    "# Cortex AI  Process Documents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be1e55-436d-4b17-a4c4-a5bf28aec5bf",
   "metadata": {
    "collapsed": false,
    "name": "heading_list_analysis_reports"
   },
   "source": [
    "Below is a list of PDFS for Analyst Reports analysing snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a6bb6-d83e-49ad-b950-6c9c52ce27a5",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "list_pdfs",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "select BUILD_SCOPED_FILE_URL('@DOCUMENT_AI.ANALYST_REPORTS',RELATIVE_PATH), * from directory(@DOCUMENT_AI.ANALYST_REPORTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4e56b-9b7d-45de-bb06-722da8493304",
   "metadata": {
    "collapsed": false,
    "name": "heading_AI_EXTRACT"
   },
   "source": [
    "## AI_PARSE_DOCUMENT and AI_COMPLETE \n",
    "\n",
    "Cortex Parse document extracts all the text out of the document which will help make them searchable.  Below uses markdown to distinguish breaks between text to add formatting and additional context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44e1f8-5c57-4072-8a6b-29398fa82995",
   "metadata": {
    "language": "sql",
    "name": "parsed_data"
   },
   "outputs": [],
   "source": "CREATE TABLE IF NOT EXISTS DOCUMENT_AI.PARSED_ANALYST_REPORTS AS\n\n SELECT \n        RELATIVE_PATH,\n        AI_PARSE_DOCUMENT(\n        TO_FILE('@DOCUMENT_AI.ANALYST_REPORTS', RELATIVE_PATH),\n            {'mode': 'LAYOUT'}) EXTRACTED_DATA\n        FROM DIRECTORY('@DOCUMENT_AI.ANALYST_REPORTS');\n\nSELECT *, EXTRACTED_DATA:content::text, EXTRACTED_DATA:metadata:pageCount FROM DOCUMENT_AI.PARSED_ANALYST_REPORTS"
  },
  {
   "cell_type": "markdown",
   "id": "77271ddc-a48c-474b-8ddc-fb1518be1be2",
   "metadata": {
    "collapsed": false,
    "name": "cortex_complete"
   },
   "source": "You will now leverage Cortex Complete to Extract key piece of information using an LLM of choice.  You will  see, that it utlises structured response formats to ensure the result is exactly what is expected."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e282d6-8dd1-4714-9415-e2c2530a6fd2",
   "metadata": {
    "language": "sql",
    "name": "Use_AI_Complete_for_same_method"
   },
   "outputs": [],
   "source": "CREATE TABLE IF NOT EXISTS DOCUMENT_AI.AI_EXTRACT_ANALYST_REPORTS_ADVANCED AS\nSELECT \n    RELATIVE_PATH,\n    EXTRACTED_DATA:content::text CONTENT,\n    EXTRACTED_DATA:metadata:pageCount PAGE_COUNT,\n    \n    -- Use AI_COMPLETE with structured output schema\n    AI_COMPLETE(\n        model => 'claude-4-sonnet',\n        prompt => CONCAT(\n            'Extract the following information from this analyst report:\\n',\n            '1. Report creation date - assume the first of the month if the date is not in full (or first of the financial year if only the year is supplied.  i need an actual date in the correct format\\n',\n            '2. Name of the report provider/research firm - Apex Analytics, Sterling Partners, Veridian Capital, Pinnacle Growth Investors, Momentum Metrics, Quant-Vestor Consensus Point \\n',\n            '3. Stock rating (BUY, SELL, HOLD, or EQUAL-WEIGHT)\\n',\n            '4. Close price value. NO VALUE if not known\\n',\n            '5. Price target value NO VALUE if UNKNOWN\\n',\n            '6. Latest revenue growth YoY this will be as a percentage between 0 and 100 NO VALUE if not known\\n\\n',\n            'Document content:\\n',\n            CONTENT\n        ),\n        response_format => {\n            'type': 'json',\n            'schema': {\n                'type': 'object',\n                'properties': {\n                    'date_report': {'type': 'string', 'description': 'Date when the report was created'},\n                    'name_of_report_provider': {'type': 'string', 'description': 'Name of the research firm or report provider'},\n                    'rating': {'type': 'string', 'enum': ['BUY', 'SELL', 'HOLD', 'EQUAL-WEIGHT'], 'description': 'Stock rating recommendation'},\n                    'close_price': {'type': 'number', 'description': 'Close price value'},\n                    'price_target': {'type': 'number', 'description': 'Price target value'},\n                    'growth': {'type': 'number', 'description': 'Latest revenue growth YoY'}\n                },\n                'required': ['date_report', 'name_of_report_provider', 'rating']\n            }\n        }\n    ) AS EXTRACTED_DATA\n\nFROM DOCUMENT_AI.PARSED_ANALYST_REPORTS;\n\nselect * from DOCUMENT_AI.AI_EXTRACT_ANALYST_REPORTS_ADVANCED"
  },
  {
   "cell_type": "markdown",
   "id": "fd90238c-74cf-4d0f-b706-419e4b63d98f",
   "metadata": {
    "name": "readable_view",
    "collapsed": false
   },
   "source": "Let's now create a view to transform the JSON into something much more readable."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e0bc4-8bf2-4ef3-87aa-97ddfae8b659",
   "metadata": {
    "language": "sql",
    "name": "create_view_strctured_table"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE VIEW DOCUMENT_AI.AI_EXTRACT_REPORTS_STRUCTURED_ADVANCED AS\n",
    "SELECT \n",
    "    RELATIVE_PATH,\n",
    "    PAGE_COUNT,\n",
    "    CONTENT AS FULL_TEXT,\n",
    "    \n",
    "    -- Extract individual fields from the structured JSON response\n",
    "    EXTRACTED_DATA:date_report::text AS DATE_REPORT,\n",
    "    EXTRACTED_DATA:name_of_report_provider::text AS NAME_OF_REPORT_PROVIDER,\n",
    "    EXTRACTED_DATA:rating::text AS RATING,\n",
    "    EXTRACTED_DATA:close_price::float AS CLOSE_PRICE,\n",
    "    EXTRACTED_DATA:price_target::float AS PRICE_TARGET,\n",
    "    EXTRACTED_DATA:growth::integer AS GROWTH\n",
    "    \n",
    "FROM DOCUMENT_AI.AI_EXTRACT_ANALYST_REPORTS_ADVANCED;\n",
    "\n",
    "SELECT * FROM DOCUMENT_AI.AI_EXTRACT_REPORTS_STRUCTURED_ADVANCED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a0c7b-8ed2-4fa1-acf0-b02ba5b51123",
   "metadata": {
    "collapsed": false,
    "name": "heading_ai_agg",
    "resultHeight": 102
   },
   "source": "### Using AI_AGG\nYou will notice that some of these reports can be quite long.  Let's use **AI_AGG** to summarise them"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57464ee-4379-4900-b0f7-6981050a4778",
   "metadata": {
    "language": "sql",
    "name": "ai_agg"
   },
   "outputs": [],
   "source": "CREATE TABLE IF NOT EXISTS DOCUMENT_AI.ANALYST_REPORTS_ALL_DATA AS\nSELECT \n    RELATIVE_PATH,\n    BUILD_SCOPED_FILE_URL('@DOCUMENT_AI.ANALYST_REPORTS',RELATIVE_PATH)FILE_URL,\n    RATING,\n    DATE_REPORT,\n    any_value(CLOSE_PRICE) CLOSE_PRICE,\n    any_value(PRICE_TARGET) PRICE_TARGET,\n    any_value(GROWTH) GROWTH,\n    NAME_OF_REPORT_PROVIDER,\n    'ANALYST_REPORTS' AS DOCUMENT_TYPE,\n    SPLIT_PART(RELATIVE_PATH, '/', 1)::text AS DOCUMENT,\n    AI_AGG(FULL_TEXT, 'summarize the analyst reports in no more than 100 words') AS SUMMARY,\n    FULL_TEXT  -- Include full text in summary table too\nFROM DOCUMENT_AI.AI_EXTRACT_REPORTS_STRUCTURED_ADVANCED\nGROUP BY RELATIVE_PATH, RATING, DATE_REPORT, NAME_OF_REPORT_PROVIDER, FULL_TEXT;\n\nSELECT * FROM DOCUMENT_AI.ANALYST_REPORTS_ALL_DATA;"
  },
  {
   "cell_type": "markdown",
   "id": "d856b4b9-a2e3-419f-a828-56cfa160a06a",
   "metadata": {
    "collapsed": false,
    "name": "head_pdf_viewer"
   },
   "source": "### A closer look at the PDFS,  \n\nThe PDF Viewer belowis built by streamlit.  You will be able to select a report with the drop down list and then see summary information which has been captured by **AISQL**.\n\nUnder the summary, you will see the original PDF side by side to the text that has been extracted.  You will notice that any formatting has been converted to markdown.  This makes it easier to read. Markdown can also be used as a way for chunking the data. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3be0ad-f93e-4513-9675-1663b2ab5a34",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "pdf_viewer",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark import functions as F\n",
    "import pypdfium2 as pdfium\n",
    "\n",
    "st.title(\"Equity Research Reports\")\n",
    "session = get_active_session()\n",
    "\n",
    "# Get all reports from the single table\n",
    "reports_table = session.table('DOCUMENT_AI.ANALYST_REPORTS_ALL_DATA')\n",
    "report_list = reports_table.select('RELATIVE_PATH')\n",
    "\n",
    "# Select a report\n",
    "file_id = st.selectbox('Select Report:', report_list)\n",
    "\n",
    "# Get the details for the selected report\n",
    "doc_details = reports_table.filter(F.col('RELATIVE_PATH') == file_id).limit(1)\n",
    "doc_details_pd = doc_details.to_pandas()\n",
    "\n",
    "# Display report details\n",
    "st.markdown('#### Report Details')\n",
    "col1, col2, col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "    st.markdown(f'''__Report Date:__ {doc_details_pd.DATE_REPORT.iloc[0]}''')\n",
    "    st.markdown(f'''__Research Firm:__ {doc_details_pd.NAME_OF_REPORT_PROVIDER.iloc[0]}''')\n",
    "    \n",
    "with col2:\n",
    "    st.markdown(f'''__Close Price:__ {doc_details_pd.CLOSE_PRICE.iloc[0]}''')\n",
    "    st.markdown(f'''__Price Target:__ {doc_details_pd.PRICE_TARGET.iloc[0]}''')\n",
    "\n",
    "with col3:\n",
    "    st.markdown(f'''__Recommendation:__ {doc_details_pd.RATING.iloc[0]}''')\n",
    "    st.markdown(f'''__Growth (YoY):__ {doc_details_pd.GROWTH.iloc[0]}%''')\n",
    "\n",
    "st.markdown(f'''__Summary:__ {doc_details_pd.SUMMARY.iloc[0]}''')\n",
    "\n",
    "# Helper functions for PDF navigation\n",
    "def display_pdf_page():\n",
    "    pdf = st.session_state['pdf_doc']\n",
    "    page = pdf[st.session_state['pdf_page']]\n",
    "    bitmap = page.render(scale=8, rotation=0)\n",
    "    pil_image = bitmap.to_pil()\n",
    "    st.image(pil_image)\n",
    "\n",
    "def next_pdf_page():\n",
    "    if st.session_state.pdf_page + 1 >= len(st.session_state['pdf_doc']):\n",
    "        st.session_state.pdf_page = 0\n",
    "    else:\n",
    "        st.session_state.pdf_page += 1\n",
    "\n",
    "def previous_pdf_page():\n",
    "    if st.session_state.pdf_page > 0:\n",
    "        st.session_state.pdf_page -= 1\n",
    "\n",
    "# PDF viewer section\n",
    "st.divider()\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    st.markdown('#### RAW PDF STORED IN FILE STORE')\n",
    "    \n",
    "    if file_id:\n",
    "        # Initialize session state for PDF viewing\n",
    "        if 'pdf_page' not in st.session_state:\n",
    "            st.session_state['pdf_page'] = 0\n",
    "        if 'pdf_url' not in st.session_state:\n",
    "            st.session_state['pdf_url'] = file_id    \n",
    "        if 'pdf_doc' not in st.session_state or st.session_state['pdf_url'] != file_id:\n",
    "            pdf_stream = session.file.get_stream(f\"@DOCUMENT_AI.ANALYST_REPORTS/{file_id}\")\n",
    "            pdf = pdfium.PdfDocument(pdf_stream)\n",
    "            st.session_state['pdf_doc'] = pdf\n",
    "            st.session_state['pdf_url'] = file_id\n",
    "            st.session_state['pdf_page'] = 0\n",
    "        \n",
    "        # Navigation controls\n",
    "        nav_col1, nav_col2, nav_col3 = st.columns(3)\n",
    "        with nav_col1:\n",
    "            st.button(\"‚èÆÔ∏è Previous\", on_click=previous_pdf_page)\n",
    "        with nav_col2:\n",
    "            st.write(f\"page {st.session_state['pdf_page'] + 1} of {len(st.session_state['pdf_doc'])} pages\")\n",
    "        with nav_col3:\n",
    "            st.button(\"Next ‚è≠Ô∏è\", on_click=next_pdf_page)\n",
    "        \n",
    "        # Display the PDF page\n",
    "        display_pdf_page()\n",
    "\n",
    "with col2:\n",
    "    st.markdown('#### EXTRACTED TEXT FROM PDFS')\n",
    "    with st.container(height=1000):\n",
    "        st.markdown(doc_details_pd.FULL_TEXT.iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2793e3-69c9-4140-9cef-e8370b102ca7",
   "metadata": {
    "collapsed": false,
    "name": "heading_ai_summarize_agg"
   },
   "source": "#### AI_AGG (summarized)\n\nYou may wish to have a summary of data from all the reports.  This is what **AI_AGG can summarize unstructured data accross multiple rows.**  The groupby gives you the level of aggregation making AISQL concepts work in a similar way to summarizing measures in SQL."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1516a91-aad2-4bbf-9d22-71ca8c19b2bc",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "AI_SUMMARIZE_AGG"
   },
   "outputs": [],
   "source": "CREATE table IF not exists DOCUMENT_AI.REPORT_PROVIDER_SUMMARY AS\nSELECT NAME_OF_REPORT_PROVIDER, AI_AGG(FULL_TEXT,'summarize the analyst reports in chronological order in no more than 500 words and compare what they have said to get an impartial view on the SNOW concensious') SUMMARY FROM DOCUMENT_AI.ANALYST_REPORTS_ALL_DATA GROUP BY ALL;\n\nselect * from DOCUMENT_AI.REPORT_PROVIDER_SUMMARY"
  },
  {
   "cell_type": "markdown",
   "id": "b1a94c45-9f2f-40b7-8226-cbf54d6e79a0",
   "metadata": {
    "collapsed": false,
    "name": "view_summary_h"
   },
   "source": [
    "And this is how we can view the summaries in streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a113a7b-d216-4253-9dc3-42969b388bf1",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "view_summarized_reports"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark import types as T\n",
    "session = get_active_session()\n",
    "summary_reports = session.table('DOCUMENT_AI.REPORT_PROVIDER_SUMMARY')\n",
    "provider_filter = st.radio('Choose Provider',summary_reports.select('NAME_OF_REPORT_PROVIDER'))\n",
    "st.markdown('#### Summarised Reports')\n",
    "st.write(session.table('DOCUMENT_AI.REPORT_PROVIDER_SUMMARY').filter(F.col('NAME_OF_REPORT_PROVIDER')==provider_filter).to_pandas().SUMMARY.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684a46f-47ca-467c-a3a4-ffff3ee82a75",
   "metadata": {
    "collapsed": false,
    "name": "heading_extract_tables"
   },
   "source": [
    "### Using AI_EXTRACT to extract tables from Financial Reports for SNOW plus other tickers\n",
    "Please note the data is synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0fcb1-ffaa-46e9-942c-c616c920b4ae",
   "metadata": {
    "language": "sql",
    "name": "financial_reports_scoped_url"
   },
   "outputs": [],
   "source": [
    "select BUILD_SCOPED_FILE_URL('@DOCUMENT_AI.FINANCIAL_REPORTS',RELATIVE_PATH), * from directory(@DOCUMENT_AI.FINANCIAL_REPORTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26ce0c-9a39-4466-a27f-c95fc36c7de2",
   "metadata": {
    "collapsed": false,
    "name": "heading_view_tabular_pdfs"
   },
   "source": [
    "Let's have a look at what the reports look like.  You will note that the reports consist of tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47761856-714e-4977-995b-43d7e4f4e6e3",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "preview_financial_reports"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark import functions as F\n",
    "import pypdfium2 as pdfium\n",
    "\n",
    "st.title(\"Financial Reports Preview\")\n",
    "session = get_active_session()\n",
    "\n",
    "# Get list of financial reports from directory (same as cell3)\n",
    "financial_reports_df = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        RELATIVE_PATH,\n",
    "        BUILD_SCOPED_FILE_URL('@DOCUMENT_AI.FINANCIAL_REPORTS', RELATIVE_PATH) AS FILE_URL,\n",
    "        SIZE,\n",
    "        LAST_MODIFIED\n",
    "    FROM DIRECTORY('@DOCUMENT_AI.FINANCIAL_REPORTS')\n",
    "\"\"\")\n",
    "\n",
    "# Select a report\n",
    "file_list = financial_reports_df.select('RELATIVE_PATH')\n",
    "file_id = st.selectbox('Select Financial Report:', file_list)\n",
    "\n",
    "# Get file details\n",
    "file_details = financial_reports_df.filter(F.col('RELATIVE_PATH') == file_id).to_pandas()\n",
    "\n",
    "if not file_details.empty:\n",
    "    st.markdown('#### File Details')\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        st.markdown(f'''__File Name:__ {file_details.RELATIVE_PATH.iloc[0]}''')\n",
    "        st.markdown(f'''__File Size:__ {file_details.SIZE.iloc[0]:,} bytes''')\n",
    "    \n",
    "    with col2:\n",
    "        st.markdown(f'''__Last Modified:__ {file_details.LAST_MODIFIED.iloc[0]}''')\n",
    "    \n",
    "    # Helper functions for PDF navigation\n",
    "    def display_pdf_page():\n",
    "        pdf = st.session_state['pdf_doc_fin']\n",
    "        page = pdf[st.session_state['pdf_page_fin']]\n",
    "        bitmap = page.render(scale=8, rotation=0)\n",
    "        pil_image = bitmap.to_pil()\n",
    "        st.image(pil_image)\n",
    "    \n",
    "    def next_pdf_page():\n",
    "        if st.session_state.pdf_page_fin + 1 >= len(st.session_state['pdf_doc_fin']):\n",
    "            st.session_state.pdf_page_fin = 0\n",
    "        else:\n",
    "            st.session_state.pdf_page_fin += 1\n",
    "    \n",
    "    def previous_pdf_page():\n",
    "        if st.session_state.pdf_page_fin > 0:\n",
    "            st.session_state.pdf_page_fin -= 1\n",
    "    \n",
    "    # PDF viewer\n",
    "    st.divider()\n",
    "    st.markdown('#### PDF VIEWER')\n",
    "    \n",
    "    if file_id:\n",
    "        # Initialize session state for PDF viewing\n",
    "        if 'pdf_page_fin' not in st.session_state:\n",
    "            st.session_state['pdf_page_fin'] = 0\n",
    "        if 'pdf_url_fin' not in st.session_state:\n",
    "            st.session_state['pdf_url_fin'] = file_id    \n",
    "        if 'pdf_doc_fin' not in st.session_state or st.session_state['pdf_url_fin'] != file_id:\n",
    "            pdf_stream = session.file.get_stream(f\"@DOCUMENT_AI.FINANCIAL_REPORTS/{file_id}\")\n",
    "            pdf = pdfium.PdfDocument(pdf_stream)\n",
    "            st.session_state['pdf_doc_fin'] = pdf\n",
    "            st.session_state['pdf_url_fin'] = file_id\n",
    "            st.session_state['pdf_page_fin'] = 0\n",
    "        \n",
    "        # Show total pages\n",
    "        total_pages = len(st.session_state['pdf_doc_fin'])\n",
    "        st.markdown(f'__Total Pages:__ {total_pages}')\n",
    "        \n",
    "        # Navigation controls\n",
    "        nav_col1, nav_col2, nav_col3 = st.columns(3)\n",
    "        with nav_col1:\n",
    "            st.button(\"‚èÆÔ∏è Previous\", on_click=previous_pdf_page, key=\"prev_fin\")\n",
    "        with nav_col2:\n",
    "            st.write(f\"page {st.session_state['pdf_page_fin'] + 1} of {total_pages}\")\n",
    "        with nav_col3:\n",
    "            st.button(\"Next ‚è≠Ô∏è\", on_click=next_pdf_page, key=\"next_fin\")\n",
    "        \n",
    "        # Display the PDF page\n",
    "        display_pdf_page()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d353e9f-7de3-46ee-b6e0-9717f3c45e1a",
   "metadata": {
    "collapsed": false,
    "name": "head_ai_extract_table"
   },
   "source": [
    "Here, you will extract the tables using AI extract.  this time, it will extract arrays of data which will formulate tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc938a-5a65-4a7f-aa27-c805567bed37",
   "metadata": {
    "language": "sql",
    "name": "extract_table",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE DOCUMENT_AI.FINANCIAL_REPORTS AS\nSELECT \n    RELATIVE_PATH,\n    AI_EXTRACT(\n        file => TO_FILE('@DOCUMENT_AI.FINANCIAL_REPORTS', RELATIVE_PATH),\n        responseFormat => {\n            'schema': {\n                'type': 'object',\n                'properties': {\n                    'company_name': {\n                        'description': 'Company name from the header',\n                        'type': 'string'\n                    },\n                    'ticker': {\n                        'description': 'Stock ticker symbol from the header (e.g., SNOW, ICBG, QRYQ, DFLX, STRM, VLTA, CTLG, NRNT)',\n                        'type': 'string'\n                    },\n                    'report_period': {\n                        'description': 'Report period (Q2 FY2025)',\n                        'type': 'string'\n                    },\n                    'income_statement': {\n                        'description': 'Consolidated Statement of Operations table',\n                        'type': 'object',\n                        'properties': {\n                            'line_item': {\n                                'description': 'First column: line item names',\n                                'type': 'array'\n                            },\n                            'q2_fy2025': {\n                                'description': 'Second column: Q2 FY2025 amounts',\n                                'type': 'array'\n                            },\n                            'q2_fy2024': {\n                                'description': 'Third column: Q2 FY2024 amounts',\n                                'type': 'array'\n                            }\n                        }\n                    },\n                    'customer_metrics': {\n                        'description': 'Customer Growth and Retention Metrics table',\n                        'type': 'object',\n                        'properties': {\n                            'metric': {\n                                'description': 'First column: metric names',\n                                'type': 'array'\n                            },\n                            'q2_fy2025': {\n                                'description': 'Second column: Q2 FY2025 values',\n                                'type': 'array'\n                            }\n                        }\n                    },\n                    'kpi_metrics': {\n                        'description': 'Key Performance Indicators table',\n                        'type': 'object',\n                        'properties': {\n                            'metric': {\n                                'description': 'First column: metric names',\n                                'type': 'array'\n                            },\n                            'value': {\n                                'description': 'Second column: values',\n                                'type': 'array'\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    ) AS EXTRACTED_DATA\nFROM DIRECTORY('@DOCUMENT_AI.FINANCIAL_REPORTS');\n\nSELECT * FROM DOCUMENT_AI.FINANCIAL_REPORTS;"
  },
  {
   "cell_type": "markdown",
   "id": "dec24c94-5aca-4cae-b5e4-a79391b33da1",
   "metadata": {
    "collapsed": false,
    "name": "heading_views"
   },
   "source": [
    "Now the tables have been extracted in objects, these can now be parsed as views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23644a85-de07-46b4-b5ae-79ca5e2a554a",
   "metadata": {
    "language": "sql",
    "name": "income_statement"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE VIEW DOCUMENT_AI.VW_INCOME_STATEMENT AS\nWITH income_data AS (\n    SELECT \n        RELATIVE_PATH,\n        EXTRACTED_DATA:response:ticker::text AS TICKER,\n        EXTRACTED_DATA:response:company_name::text AS COMPANY,\n        EXTRACTED_DATA:response:report_period::text AS PERIOD,\n        EXTRACTED_DATA:response:income_statement:line_item AS LINE_ITEMS,\n        EXTRACTED_DATA:response:income_statement:q2_fy2025 AS Q2_2025,\n        EXTRACTED_DATA:response:income_statement:q2_fy2024 AS Q2_2024\n    FROM DOCUMENT_AI.FINANCIAL_REPORTS\n    WHERE EXTRACTED_DATA:response:income_statement IS NOT NULL\n)\nSELECT \n    COMPANY,\n    TICKER,\n    PERIOD,\n    idx.VALUE::text AS LINE_ITEM,\n    Q2_2025[idx.INDEX]::text AS Q2_FY2025,\n    Q2_2024[idx.INDEX]::text AS Q2_FY2024,\n    idx.INDEX + 1 AS ROW_NUM,\n    RELATIVE_PATH\nFROM income_data,\nLATERAL FLATTEN(input => LINE_ITEMS) idx\nORDER BY COMPANY, idx.INDEX;\n\nselect * from DOCUMENT_AI.VW_INCOME_STATEMENT"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc1d44-399a-44f6-b270-9edc019b40e7",
   "metadata": {
    "language": "sql",
    "name": "customer_metrics"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE VIEW DOCUMENT_AI.VW_FINANCIAL_SUMMARY AS\nSELECT \n    EXTRACTED_DATA:response:company_name::text AS COMPANY,\n    EXTRACTED_DATA:response:ticker::text AS TICKER,\n    EXTRACTED_DATA:response:report_period::text AS PERIOD,\n    EXTRACTED_DATA:response:income_statement:q2_fy2025[2]::text AS TOTAL_REVENUE_Q2_2025,\n    EXTRACTED_DATA:response:income_statement:q2_fy2024[2]::text AS TOTAL_REVENUE_Q2_2024,\n    EXTRACTED_DATA:response:customer_metrics:q2_fy2025[0]::text AS TOTAL_CUSTOMERS,\n    EXTRACTED_DATA:response:customer_metrics:q2_fy2025[4]::text AS NRR,\n    EXTRACTED_DATA:response:kpi_metrics:value[0]::text AS YOY_GROWTH,\n    EXTRACTED_DATA:response:kpi_metrics:value[1]::text AS GROSS_MARGIN,\n    EXTRACTED_DATA:response:kpi_metrics:value[2]::text AS OPERATING_MARGIN,\n    EXTRACTED_DATA:response:kpi_metrics:value[3]::text AS FREE_CASH_FLOW,\n    RELATIVE_PATH\nFROM DOCUMENT_AI.FINANCIAL_REPORTS\nORDER BY COMPANY;\n\nSELECT * FROM DOCUMENT_AI.VW_FINANCIAL_SUMMARY;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df8870-6103-4a58-a4ea-6ec4da6f6064",
   "metadata": {
    "language": "sql",
    "name": "kpi_metrics"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE VIEW DOCUMENT_AI.VW_KPI_METRICS AS\nWITH kpi_data AS (\n    SELECT \n        RELATIVE_PATH,\n        EXTRACTED_DATA:response:company_name::text AS COMPANY,\n        EXTRACTED_DATA:response:ticker::text AS TICKER,\n        EXTRACTED_DATA:response:report_period::text AS PERIOD,\n        EXTRACTED_DATA:response:kpi_metrics:metric AS METRICS,\n        EXTRACTED_DATA:response:kpi_metrics:value AS KPI_VALUES\n    FROM DOCUMENT_AI.FINANCIAL_REPORTS\n    WHERE EXTRACTED_DATA:response:kpi_metrics IS NOT NULL\n)\nSELECT \n    RELATIVE_PATH,\n    COMPANY,\n    TICKER,\n    PERIOD,\n    idx.VALUE::text AS KPI_NAME,\n    KPI_VALUES[idx.INDEX]::text AS KPI_VALUE,\n    idx.INDEX + 1 AS ROW_NUM\nFROM kpi_data,\nLATERAL FLATTEN(input => METRICS) idx\nORDER BY COMPANY, idx.INDEX;\n\nSELECT * FROM DOCUMENT_AI.VW_KPI_METRICS;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5490f9-39c5-4d40-98d7-ebb6ae4a0448",
   "metadata": {
    "language": "sql",
    "name": "parse_images_from_kpi_graphics"
   },
   "outputs": [],
   "source": [
    "select BUILD_SCOPED_FILE_URL('@DOCUMENT_AI.INFOGRAPHICS',RELATIVE_PATH), * from directory(@DOCUMENT_AI.INFOGRAPHICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ff0d0-6a1b-40e9-8bab-e0a840935047",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "view_infographic_files"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark import functions as F\n",
    "\n",
    "st.title(\"Infographics Dashboard - All Companies\")\n",
    "session = get_active_session()\n",
    "\n",
    "# Get all infographics from directory\n",
    "infographics_df = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        RELATIVE_PATH,\n",
    "        BUILD_SCOPED_FILE_URL('@DOCUMENT_AI.INFOGRAPHICS', RELATIVE_PATH) AS FILE_URL,\n",
    "        SIZE\n",
    "    FROM DIRECTORY('@DOCUMENT_AI.INFOGRAPHICS')\n",
    "    WHERE RELATIVE_PATH LIKE '%FY25-Q2.png'\n",
    "    ORDER BY RELATIVE_PATH\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "st.markdown(f\"### {len(infographics_df)} Infographics - Q2 FY2025\")\n",
    "st.divider()\n",
    "\n",
    "# Display in 2 rows of 4 columns\n",
    "if len(infographics_df) > 0:\n",
    "    # Row 1 - First 4 companies\n",
    "    cols_row1 = st.columns(4)\n",
    "    for idx in range(min(4, len(infographics_df))):\n",
    "        with cols_row1[idx]:\n",
    "            row = infographics_df.iloc[idx]\n",
    "            # Extract company ticker from filename\n",
    "            company = row['RELATIVE_PATH'].split('_')[0]\n",
    "            st.markdown(f\"**{company}**\")\n",
    "            \n",
    "            # Read and display image\n",
    "            image_bytes = session.file.get_stream(f\"@DOCUMENT_AI.INFOGRAPHICS/{row['RELATIVE_PATH']}\").read()\n",
    "            st.image(image_bytes)\n",
    "            \n",
    "            # Show file size\n",
    "            st.caption(f\"{row['SIZE']:,} bytes\")\n",
    "    \n",
    "    # Row 2 - Next 4 companies\n",
    "    if len(infographics_df) > 4:\n",
    "        st.divider()\n",
    "        cols_row2 = st.columns(4)\n",
    "        for idx in range(4, min(8, len(infographics_df))):\n",
    "            with cols_row2[idx - 4]:\n",
    "                row = infographics_df.iloc[idx]\n",
    "                # Extract company ticker from filename\n",
    "                company = row['RELATIVE_PATH'].split('_')[0]\n",
    "                st.markdown(f\"**{company}**\")\n",
    "                \n",
    "                # Read and display image\n",
    "                image_bytes = session.file.get_stream(f\"@DOCUMENT_AI.INFOGRAPHICS/{row['RELATIVE_PATH']}\").read()\n",
    "                st.image(image_bytes)\n",
    "                \n",
    "                # Show file size\n",
    "                st.caption(f\"{row['SIZE']:,} bytes\")\n",
    "else:\n",
    "    st.warning(\"No infographics found in @DOCUMENT_AI.INFOGRAPHICS stage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d1495-ac59-453c-ae50-ea29b487730e",
   "metadata": {
    "name": "header_ai_extract",
    "collapsed": false
   },
   "source": "### AI_EXTRACT \nfor Infographics - SIMPLE FORMAT for structured outputs - using questions with field names.\n\n### AI_COMPLETE \nMulti Modal Analytics to get an over all understanding of each image\nIndividual questions instead of table schema"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba61f1-7bc4-44c6-b21b-f159108679d3",
   "metadata": {
    "language": "sql",
    "name": "extracted_infographics"
   },
   "outputs": [],
   "source": "CREATE or replace table DOCUMENT_AI.INFOGRAPHIC_METRICS_EXTRACTED AS\nSELECT \n    RELATIVE_PATH,\n    SPLIT_PART(RELATIVE_PATH, '_', 1) AS COMPANY_TICKER,\n    \n    -- Use simple question-answer format (NO table schema)\n    AI_EXTRACT(\n        file => TO_FILE('@DOCUMENT_AI.INFOGRAPHICS', RELATIVE_PATH),\n        responseFormat => {\n            'text': 'what is the business mission statement',\n            'company_name': 'What is the full company name?',\n            'ticker': 'What is the ticker symbol?',\n            'report_period': 'What is the report period shown?',\n            'total_revenue': 'What is the Total Revenue amount shown?',\n            'yoy_growth': 'What is the YoY Growth percentage shown?',\n            'product_revenue': 'What is the Product Revenue amount?',\n            'services_revenue': 'What is the Services or Professional Services Revenue amount?',\n            'total_customers': 'What is the Total Customers number?',\n            'customers_1m_plus': 'How many customers with $1M+ Revenue are shown?',\n            'nrr': 'What is the Net Revenue Retention or NRR percentage?',\n            'gross_margin': 'What is the Gross Margin percentage?',\n            'operating_margin': 'What is the Operating Margin percentage?',\n            'free_cash_flow': 'What is the Free Cash Flow amount?',\n            'rpo': 'What is the RPO or Remaining Performance Obligations amount?',\n            'rpo_growth': 'What is the RPO Growth percentage?'\n        }\n    ) AS EXTRACTED_DATA,\n    AI_COMPLETE('claude-4-sonnet','DESCRIBE THE BRANDING which include what kind of meaning might be read into the colour schemes, mission and key overview FROM THIS IMAGE.  dont return any verbiage and just the markdown text',TO_FILE('@DOCUMENT_AI.INFOGRAPHICS', RELATIVE_PATH)) BRANDING\n\nFROM DIRECTORY('@DOCUMENT_AI.INFOGRAPHICS');\n\nSELECT * FROM DOCUMENT_AI.INFOGRAPHIC_METRICS_EXTRACTED;\n\n-- Create a clean view\nCREATE OR REPLACE VIEW DOCUMENT_AI.VW_INFOGRAPHIC_METRICS AS\nSELECT \n    COMPANY_TICKER,\n    RELATIVE_PATH,\n    EXTRACTED_DATA:response:text::text AS TEXT,\n    EXTRACTED_DATA:response:company_name::text AS COMPANY_NAME,\n    EXTRACTED_DATA:response:ticker::text AS TICKER,\n    EXTRACTED_DATA:response:report_period::text AS REPORT_PERIOD,\n    EXTRACTED_DATA:response:total_revenue::text AS TOTAL_REVENUE,\n    EXTRACTED_DATA:response:yoy_growth::text AS YOY_GROWTH,\n    EXTRACTED_DATA:response:product_revenue::text AS PRODUCT_REVENUE,\n    EXTRACTED_DATA:response:services_revenue::text AS SERVICES_REVENUE,\n    EXTRACTED_DATA:response:total_customers::text AS TOTAL_CUSTOMERS,\n    EXTRACTED_DATA:response:customers_1m_plus::text AS CUSTOMERS_1M_PLUS,\n    EXTRACTED_DATA:response:nrr::text AS NET_REVENUE_RETENTION,\n    EXTRACTED_DATA:response:gross_margin::text AS GROSS_MARGIN,\n    EXTRACTED_DATA:response:operating_margin::text AS OPERATING_MARGIN,\n    EXTRACTED_DATA:response:free_cash_flow::text AS FREE_CASH_FLOW,\n    EXTRACTED_DATA:response:rpo::text AS RPO,\n    EXTRACTED_DATA:response:rpo_growth::text AS RPO_GROWTH,\n    BRANDING\nFROM DOCUMENT_AI.INFOGRAPHIC_METRICS_EXTRACTED;\n\nSELECT * FROM DOCUMENT_AI.VW_INFOGRAPHIC_METRICS\nORDER BY COMPANY_TICKER;\n"
  },
  {
   "cell_type": "markdown",
   "id": "e9a171fb-8704-445b-9d0a-b29a320de7b8",
   "metadata": {
    "name": "hesder_email_exttaction",
    "collapsed": false
   },
   "source": "## Email Extraction\n\nYou might have HTML content delivered by Emails - **AI_EXTRACT** is useful to take out these key values for further analysis"
  },
  {
   "cell_type": "code",
   "id": "d49f8cdb-9555-4f07-a079-80e68b78d4d4",
   "metadata": {
    "language": "sql",
    "name": "parsed_emails"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS_EXTRACTED AS\nWITH extracted AS (\n    SELECT \n        *,\n        AI_EXTRACT(\n            HTML_CONTENT,\n            {\n                'ticker': 'Extract ALL stock ticker symbols mentioned. Return as comma-separated list: SNOW, CTLG, ICBG, DFLX, QRYQ, STRM, VLTA, NRNT',\n                'rating': 'investment rating (BUY, SELL, HOLD, OVERWEIGHT, EQUAL-WEIGHT)'\n            }\n        ) AS extracted_data,\n        AI_SENTIMENT(HTML_CONTENT) AS sentiment_data\n    FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS\n),\ncleaned AS (\n    SELECT \n        *,\n        -- Remove brackets and quotes from ticker string\n        TRIM(REPLACE(REPLACE(REPLACE(\n            COALESCE(extracted_data:response:ticker::STRING, ''),\n            '[', ''), ']', ''), '\"', ''\n        )) AS ticker_clean\n    FROM extracted\n)\nSELECT \n    EMAIL_ID,\n    RECIPIENT_EMAIL,\n    SUBJECT,\n    HTML_CONTENT,\n    CREATED_AT,\n    TRIM(f.value::STRING) AS TICKER,\n    extracted_data:response:rating::STRING AS RATING,\n    sentiment_data:categories[0]:sentiment::STRING AS SENTIMENT\nFROM cleaned,\nLATERAL FLATTEN(\n    input => SPLIT(ticker_clean, ','),\n    outer => TRUE\n) f\nWHERE TRIM(f.value::STRING) NOT IN ('None', 'null', '', 'N/A', 'none')\n  AND TRIM(f.value::STRING) IS NOT NULL\n  AND LENGTH(TRIM(f.value::STRING)) > 0;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bff60314-be8a-4f31-836f-a23b2ce2c850",
   "metadata": {
    "language": "sql",
    "name": "view_parsed_emails"
   },
   "outputs": [],
   "source": "SELECT * FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS_EXTRACTED",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c465170-772d-4ece-83d0-3067396d7017",
   "metadata": {
    "language": "python",
    "name": "verify_sentiment_distribution",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# Import required libraries\nimport streamlit as st\nimport pandas as pd\nimport altair as alt\nfrom snowflake.snowpark.context import get_active_session\n\n# Get Snowflake session\nsession = get_active_session()\n\n# Title\nst.title(\"üìß Financial Analyst Email Analytics\")\n\n# Add refresh button\ncol1, col2 = st.columns([6, 1])\nwith col2:\n    if st.button(\"üîÑ Refresh Data\"):\n        st.cache_data.clear()\n        st.rerun()\n\nst.markdown(\"---\")\n\n# Load data - cache for 5 minutes\n@st.cache_data(ttl=300)\ndef load_data():\n    query = \"\"\"\n    SELECT \n        EMAIL_ID,\n        TICKER,\n        RATING,\n        SENTIMENT,\n        CREATED_AT,\n        SUBJECT,\n        DATE_TRUNC('MONTH', CREATED_AT) AS MONTH,\n        DATE_TRUNC('WEEK', CREATED_AT) AS WEEK\n    FROM ACCELERATE_AI_IN_FSI.DEFAULT_SCHEMA.EMAIL_PREVIEWS_EXTRACTED\n    WHERE TICKER IS NOT NULL\n    \"\"\"\n    return session.sql(query).to_pandas()\n\ndf = load_data()\n\n# Prominent Filters at the top\nst.subheader(\"üîç Filters\")\n\ncol1, col2, col3 = st.columns([2, 1, 1])\n\nwith col1:\n    # Ticker filter with \"All\" option\n    ticker_options = ['All'] + sorted(df['TICKER'].unique().tolist())\n    selected_ticker = st.selectbox(\n        \"Select Ticker\",\n        options=ticker_options,\n        index=0\n    )\n\nwith col2:\n    time_grouping = st.selectbox(\n        \"Time Grouping\",\n        options=[\"Week\", \"Month\"],\n        index=1\n    )\n\nwith col3:\n    # Optional: Add rating filter\n    rating_options = ['All'] + sorted([r for r in df['RATING'].dropna().unique().tolist() if r not in ['None', 'null', '']])\n    selected_rating = st.selectbox(\n        \"Filter by Rating\",\n        options=rating_options,\n        index=0\n    )\n\n# Apply filters\nfiltered_df = df.copy()\n\nif selected_ticker != 'All':\n    filtered_df = filtered_df[filtered_df['TICKER'] == selected_ticker]\n\nif selected_rating != 'All':\n    filtered_df = filtered_df[filtered_df['RATING'] == selected_rating]\n\nst.markdown(\"---\")\n\n# Metrics row - IMPROVED COMPACT VERSION\nst.markdown(\"\"\"\n    <style>\n    div[data-testid=\"metric-container\"] {\n        background-color: #f8f9fa;\n        border: 1px solid #dee2e6;\n        padding: 15px;\n        border-radius: 8px;\n        box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n    }\n    div[data-testid=\"metric-container\"] label {\n        font-size: 0.85rem !important;\n        font-weight: 600 !important;\n        color: #495057 !important;\n    }\n    div[data-testid=\"metric-container\"] [data-testid=\"stMetricValue\"] {\n        font-size: 1.8rem !important;\n        font-weight: 700 !important;\n        color: #212529 !important;\n    }\n    div[data-testid=\"metric-container\"] [data-testid=\"stMetricDelta\"] {\n        font-size: 0.75rem !important;\n    }\n    </style>\n\"\"\", unsafe_allow_html=True)\n\ncol1, col2, col3, col4 = st.columns(4)\n\nwith col1:\n    st.metric(\"üìß Emails\", f\"{len(filtered_df):,}\")\n\nwith col2:\n    st.metric(\"üè¢ Tickers\", filtered_df['TICKER'].nunique())\n\nwith col3:\n    if len(filtered_df) > 0:\n        date_range = f\"{filtered_df['CREATED_AT'].min().strftime('%b %y')} - {filtered_df['CREATED_AT'].max().strftime('%b %y')}\"\n        st.metric(\"üìÖ Period\", date_range)\n    else:\n        st.metric(\"üìÖ Period\", \"N/A\")\n\nwith col4:\n    if len(filtered_df) > 0:\n        positive_count = (filtered_df['SENTIMENT'] == 'positive').sum()\n        positive_pct = positive_count / len(filtered_df) * 100\n        st.metric(\n            \"üòä Positive\", \n            f\"{positive_pct:.0f}%\",\n            delta=f\"{positive_count} emails\"\n        )\n    else:\n        st.metric(\"üòä Positive\", \"0%\")\n\nst.markdown(\"---\")\n\n# Only show charts if we have data\nif len(filtered_df) == 0:\n    st.warning(\"No data available for the selected filters. Please adjust your selection.\")\nelse:\n    # Row 1: Rating and Sentiment Distribution\n    col1, col2 = st.columns(2)\n\n    with col1:\n        st.subheader(\"üìä Rating Distribution\")\n        \n        rating_counts = filtered_df['RATING'].value_counts().reset_index()\n        rating_counts.columns = ['Rating', 'Count']\n        \n        # Define color mapping for ratings\n        rating_colors = {\n            'BUY': '#10B981',\n            'OVERWEIGHT': '#34D399',\n            'HOLD': '#F59E0B',\n            'EQUAL-WEIGHT': '#FBBF24',\n            'UNDERWEIGHT': '#F87171',\n            'SELL': '#EF4444',\n            'OUTPERFORM': '#059669'\n        }\n        \n        rating_chart = alt.Chart(rating_counts).mark_bar().encode(\n            x=alt.X('Rating:N', sort='-y', title='Rating'),\n            y=alt.Y('Count:Q', title='Number of Emails'),\n            color=alt.Color('Rating:N', scale=alt.Scale(\n                domain=list(rating_colors.keys()),\n                range=list(rating_colors.values())\n            ), legend=None),\n            tooltip=['Rating', 'Count']\n        ).properties(\n            height=300\n        )\n        \n        st.altair_chart(rating_chart, use_container_width=True)\n        \n        # Show rating stats\n        st.dataframe(\n            rating_counts.sort_values('Count', ascending=False),\n            use_container_width=True,\n            hide_index=True\n        )\n\n    with col2:\n        st.subheader(\"üòä Sentiment Distribution\")\n        \n        sentiment_counts = filtered_df['SENTIMENT'].value_counts().reset_index()\n        sentiment_counts.columns = ['Sentiment', 'Count']\n        \n        # Define color mapping for sentiment\n        sentiment_colors = {\n            'positive': '#10B981',\n            'neutral': '#F59E0B',\n            'negative': '#EF4444',\n            'mixed': '#8B5CF6',\n            'unknown': '#6B7280'\n        }\n        \n        sentiment_chart = alt.Chart(sentiment_counts).mark_bar().encode(\n            x=alt.X('Sentiment:N', sort='-y', title='Sentiment'),\n            y=alt.Y('Count:Q', title='Number of Emails'),\n            color=alt.Color('Sentiment:N', scale=alt.Scale(\n                domain=list(sentiment_colors.keys()),\n                range=list(sentiment_colors.values())\n            ), legend=None),\n            tooltip=['Sentiment', 'Count']\n        ).properties(\n            height=300\n        )\n        \n        st.altair_chart(sentiment_chart, use_container_width=True)\n        \n        # Show sentiment stats\n        st.dataframe(\n            sentiment_counts.sort_values('Count', ascending=False),\n            use_container_width=True,\n            hide_index=True\n        )\n\n    st.markdown(\"---\")\n\n    # Row 2: Sentiment Over Time\n    st.subheader(\"üìà Sentiment Distribution Over Time\")\n\n    time_col = 'WEEK' if time_grouping == \"Week\" else 'MONTH'\n\n    sentiment_over_time = filtered_df.groupby([time_col, 'SENTIMENT']).size().reset_index(name='Count')\n    sentiment_over_time.columns = ['Date', 'Sentiment', 'Count']\n\n    sentiment_time_chart = alt.Chart(sentiment_over_time).mark_area(opacity=0.7).encode(\n        x=alt.X('Date:T', title=f'{time_grouping}'),\n        y=alt.Y('Count:Q', title='Number of Emails', stack='normalize'),\n        color=alt.Color('Sentiment:N', scale=alt.Scale(\n            domain=list(sentiment_colors.keys()),\n            range=list(sentiment_colors.values())\n        )),\n        tooltip=['Date:T', 'Sentiment:N', 'Count:Q']\n    ).properties(\n        height=400\n    )\n\n    st.altair_chart(sentiment_time_chart, use_container_width=True)\n\n    st.markdown(\"---\")\n\n    # Row 3: Rating Over Time\n    st.subheader(\"üìä Rating Distribution Over Time\")\n\n    rating_over_time = filtered_df.groupby([time_col, 'RATING']).size().reset_index(name='Count')\n    rating_over_time.columns = ['Date', 'Rating', 'Count']\n\n    rating_time_chart = alt.Chart(rating_over_time).mark_bar().encode(\n        x=alt.X('Date:T', title=f'{time_grouping}'),\n        y=alt.Y('Count:Q', title='Number of Emails'),\n        color=alt.Color('Rating:N', scale=alt.Scale(\n            domain=list(rating_colors.keys()),\n            range=list(rating_colors.values())\n        )),\n        tooltip=['Date:T', 'Rating:N', 'Count:Q']\n    ).properties(\n        height=400\n    )\n\n    st.altair_chart(rating_time_chart, use_container_width=True)\n\n    st.markdown(\"---\")\n\n    # Row 4: Ticker Analysis (only show if \"All\" is selected)\n    if selected_ticker == 'All':\n        st.subheader(\"üè¢ Analysis by Ticker\")\n\n        col1, col2 = st.columns(2)\n\n        with col1:\n            st.markdown(\"#### Sentiment by Ticker\")\n            \n            ticker_sentiment = filtered_df.groupby(['TICKER', 'SENTIMENT']).size().reset_index(name='Count')\n            \n            ticker_sentiment_chart = alt.Chart(ticker_sentiment).mark_bar().encode(\n                x=alt.X('TICKER:N', title='Ticker', sort='-y'),\n                y=alt.Y('Count:Q', title='Number of Emails'),\n                color=alt.Color('SENTIMENT:N', scale=alt.Scale(\n                    domain=list(sentiment_colors.keys()),\n                    range=list(sentiment_colors.values())\n                )),\n                tooltip=['TICKER', 'SENTIMENT', 'Count']\n            ).properties(\n                height=350\n            )\n            \n            st.altair_chart(ticker_sentiment_chart, use_container_width=True)\n\n        with col2:\n            st.markdown(\"#### Rating by Ticker\")\n            \n            ticker_rating = filtered_df.groupby(['TICKER', 'RATING']).size().reset_index(name='Count')\n            \n            ticker_rating_chart = alt.Chart(ticker_rating).mark_bar().encode(\n                x=alt.X('TICKER:N', title='Ticker', sort='-y'),\n                y=alt.Y('Count:Q', title='Number of Emails'),\n                color=alt.Color('RATING:N', scale=alt.Scale(\n                    domain=list(rating_colors.keys()),\n                    range=list(rating_colors.values())\n                )),\n                tooltip=['TICKER', 'RATING', 'Count']\n            ).properties(\n                height=350\n            )\n            \n            st.altair_chart(ticker_rating_chart, use_container_width=True)\n\n        st.markdown(\"---\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "04e1ecdf-d593-4308-ae77-f49c9b9615ee",
   "metadata": {
    "name": "summary",
    "collapsed": false
   },
   "source": "### Summary\n\nYou've now explored multiple AI-powered document processing capabilities:\n\n1. **AI_PARSE_DOCUMENT** - Extracted text and structure from PDF analyst reports\n2. **AI_EXTRACT** - Pulled structured data from financial reports and infographics\n3. **AI_COMPLETE** - Generated summaries,sentiment analysis and multimodal analytics\n4. **AI_AGG** - Summarised parsed text into digestable summaries.\n\nNext, we'll explore earnings call data transcribed from audio files using **AI_TRANSCRIBE**.\n\n"
  }
 ]
}
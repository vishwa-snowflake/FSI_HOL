{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463050b4-bef4-4c6b-bedf-d1851064869b",
   "metadata": {
    "collapsed": false,
    "name": "heading_create_service",
    "resultHeight": 183
   },
   "source": [
    "# Use AI_TRANSCRIBE to transcrbe earnings calls\n",
    "\n",
    "**AI_TRANSCRIBE**  This is a built in multimodal function which allows all the text to be transcribed **WITHOUT ANY SETUP**.  We will also leverage this during this lab\n",
    "\n",
    "\n",
    "***FOR INFORMATION***\n",
    "\n",
    "**Snowflake Public Data (Cortex knowledge Extensions)** is a product on the marketplace which include  Earnings call transcripts. In addition to the transcripts themselves, a fully managed search service is provided within the share.\n",
    "\n",
    "Click [here](https://app.snowflake.com/marketplace/listing/GZTSZ290BV65X/snowflake-public-data-products-snowflake-public-data-cortex-knowledge-extensions) to find out more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db43f053-4480-4ab8-b503-d8d15e23d9fa",
   "metadata": {
    "collapsed": false,
    "name": "run_functions",
    "resultHeight": 47
   },
   "source": [
    "####  Listen to the calls that were transcribed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991795b0-3450-429c-b642-1f49222fa581",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "select BUILD_SCOPED_FILE_URL('@DOCUMENT_AI.EARNINGS_CALLS_AUDIO',RELATIVE_PATH), * from directory(@DOCUMENT_AI.EARNINGS_CALLS_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eeffd1-5a10-46fd-be4c-83d1b2078656",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "view_each_call",
    "resultHeight": 161
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "\n",
    "files = session.sql('''SELECT RELATIVE_PATH, GET_PRESIGNED_URL('@DOCUMENT_AI.EARNINGS_CALLS',RELATIVE_PATH) URL FROM DIRECTORY (@DOCUMENT_AI.EARNINGS_CALLS)''')\n",
    "\n",
    "\n",
    "select_call = st.selectbox('Select Call:', files.select('RELATIVE_PATH'))\n",
    "\n",
    "URL = files.filter(col('RELATIVE_PATH') == select_call).select('URL').collect()[0][0]\n",
    "st.audio(URL, format=\"audio/mpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c1acd-f84d-4320-b38f-e9495a1a2971",
   "metadata": {
    "collapsed": false,
    "name": "head_transcribe"
   },
   "source": [
    "Below AI_TRANSCRIBE is used to transcribe the calls.  You will note that the granularity used is at timetamp and speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444def92-e852-442a-b3d0-5ef2fdceddba",
   "metadata": {
    "language": "sql",
    "name": "transcribe_calls"
   },
   "outputs": [],
   "source": [
    "-- With speaker labels and timestamps\n",
    "CREATE TABLE IF NOT EXISTS DEFAULT_SCHEMA.TRANSCRIBED_EARNINGS_CALLS AS\n",
    "SELECT \n",
    "    RELATIVE_PATH,\n",
    "    AI_TRANSCRIBE(\n",
    "        TO_FILE('@DOCUMENT_AI.EARNINGS_CALLS_AUDIO', RELATIVE_PATH),\n",
    "        {'timestamp_granularity': 'speaker'}\n",
    "    ) AS EXTRACTED_DATA\n",
    "FROM DIRECTORY('@DOCUMENT_AI.EARNINGS_CALLS_AUDIO');\n",
    "\n",
    "-- Query with segments (speaker turns)\n",
    "SELECT \n",
    "    RELATIVE_PATH,\n",
    "    EXTRACTED_DATA:audio_duration::float AS AUDIO_DURATION_SECONDS,\n",
    "    segment.value:start::float AS START_TIME,\n",
    "    segment.value:end::float AS END_TIME,\n",
    "    segment.value:speaker_label::text AS SPEAKER,\n",
    "    segment.value:text::text AS SEGMENT_TEXT\n",
    "FROM DOCUMENT_AI.TRANSCRIBED_EARNINGS_CALLS,\n",
    "LATERAL FLATTEN(input => EXTRACTED_DATA:segments) segment;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9effd67-3c0f-4c64-a198-6cfa458fa730",
   "metadata": {
    "collapsed": false,
    "name": "head_who_are_the_speakers"
   },
   "source": [
    "Now lets actually see who the speakers are - we can do this with AI_COMPLETE.  Please not the accuracy of the speaker might depend on the sound quality and the explicitness of the caller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb370a-a198-4414-8ac3-bcefa4042ba7",
   "metadata": {
    "language": "sql",
    "name": "who_are_the_speakers"
   },
   "outputs": [],
   "source": [
    "CREATE TABLE IF NOT EXISTS DEFAULT_SCHEMA.SPEAKER_MAPPING AS\n",
    "SELECT \n",
    "    t.RELATIVE_PATH,\n",
    "    f.value:speaker_id::STRING AS SPEAKER,\n",
    "    f.value:speaker_name::STRING AS SPEAKER_NAME\n",
    "FROM DEFAULT_SCHEMA.TRANSCRIBED_EARNINGS_CALLS t,\n",
    "LATERAL FLATTEN(\n",
    "    input => AI_COMPLETE(\n",
    "        model => 'claude-4-sonnet',\n",
    "        prompt => CONCAT(\n",
    "            'Identify all speakers in this earnings call transcript. ',\n",
    "            'Return a JSON array where each element has \"speaker_id\" and \"speaker_name\". ',\n",
    "            'Transcript: ',\n",
    "            EXTRACTED_DATA::TEXT\n",
    "        ),\n",
    "        response_format => {\n",
    "            'type': 'json',\n",
    "            'schema': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'speakers': {\n",
    "                        'type': 'array',\n",
    "                        'items': {\n",
    "                            'type': 'object',\n",
    "                            'properties': {\n",
    "                                'speaker_id': {'type': 'string', 'description': 'Speaker identifier like SPEAKER_1'},\n",
    "                                'speaker_name': {'type': 'string', 'description': 'Full name of the speaker'}\n",
    "                            },\n",
    "                            'required': ['speaker_id', 'speaker_name']\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                'required': ['speakers']\n",
    "            }\n",
    "        }\n",
    "    ):speakers\n",
    ") f;\n",
    "\n",
    "SELECT * FROM DEFAULT_SCHEMA.SPEAKER_MAPPING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098216c2-20b6-4935-b0d3-815986f9e664",
   "metadata": {
    "collapsed": false,
    "name": "heading_add_sentiment",
    "resultHeight": 47
   },
   "source": [
    "#### Add Sentiment scores to the calls\n",
    "Here, AI Sentiment is being used to generate a sentiment score for each text snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65821c72-41ad-4d5a-ab8a-fb9f290f24ec",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "with_sentiment",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE DEFAULT_SCHEMA.TRANSCRIBED_EARNINGS_CALLS_WITH_SENTIMENT AS\n",
    "\n",
    "select b.*, a.* EXCLUDE (RELATIVE_PATH, SPEAKER) from (\n",
    "SELECT *, SNOWFLAKE.CORTEX.SENTIMENT(SEGMENT_TEXT) SENTIMENT FROM (\n",
    "SELECT \n",
    "    RELATIVE_PATH,\n",
    "    EXTRACTED_DATA:audio_duration::float AS AUDIO_DURATION_SECONDS,\n",
    "    segment.value:start::float AS START_TIME,\n",
    "    segment.value:end::float AS END_TIME,\n",
    "    segment.value:speaker_label::text AS SPEAKER,\n",
    "    segment.value:text::text AS SEGMENT_TEXT\n",
    "FROM DEFAULT_SCHEMA.TRANSCRIBED_EARNINGS_CALLS,\n",
    "LATERAL FLATTEN(input => EXTRACTED_DATA:segments) segment)) a \n",
    "\n",
    "natural join DEFAULT_SCHEMA.SPEAKER_MAPPING b\n",
    "\n",
    ";\n",
    "\n",
    "SELECT * FROM DEFAULT_SCHEMA.TRANSCRIBED_EARNINGS_CALLS_WITH_SENTIMENT \n",
    "ORDER BY RELATIVE_PATH, START_TIME;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337bffc-9f87-4c3d-8739-6676a4b12549",
   "metadata": {
    "collapsed": false,
    "name": "heading_Streamlit",
    "resultHeight": 47
   },
   "source": [
    "#### Put all together in Streamlit\n",
    "Let's now have a look at the results using a visualistion in Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6068f0-ea09-47f0-b4c9-438ace28179c",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "earnings_sentiment",
    "resultHeight": 977
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "def sentiment(text):\n",
    "    return call_function('snowflake.cortex.sentiment',text)\n",
    "\n",
    "transcript_with_sentiment = session.table('DEFAULT_SCHEMA.TRANSCRIBED_EARNINGS_CALLS_WITH_SENTIMENT')\n",
    "\n",
    "st.markdown('#### Calls with Sentiment')\n",
    "\n",
    "\n",
    "st.dataframe(transcript_with_sentiment)\n",
    "col1,col2,col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "\n",
    "    st.markdown('#### Q1')\n",
    "    q1 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q1_FY2025.mp3')\n",
    "    st.line_chart(q1,\n",
    "              y='SENTIMENT',x='START_TIME',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q1.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col2:\n",
    "    q2 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q2_FY2025.mp3')\n",
    "    st.markdown('#### Q2')\n",
    "    st.line_chart(q2,\n",
    "              y='SENTIMENT',x='START_TIME',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q2.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col3:\n",
    "    \n",
    "    st.markdown('#### Q3')\n",
    "    q3 = transcript_with_sentiment.filter(col('RELATIVE_PATH')=='EARNINGS_Q3_FY2025.mp3')\n",
    "    st.line_chart(q3,\n",
    "              y='SENTIMENT',x='START_TIME',color = '#FF9F36')\n",
    "    st.metric('Average Sentiment',q3.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b3428-ea67-40ca-a1b0-9263ea9a5d02",
   "metadata": {
    "collapsed": false,
    "name": "hard_to_read"
   },
   "source": [
    "You will see that the line charts are very hard to read.  Also with such a small snippet of information, it is difficult to get a good sentiment score.  Unlike the chunking which you did with the Analyst reports, this time we are going to group snippets of data together for every 60 seconds and then create an average sentiment for each minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d30301-7651-48e9-b3b6-9d1f9b480323",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "sentiment_minutes",
    "resultHeight": 464
   },
   "outputs": [],
   "source": [
    "grouped = transcript_with_sentiment.with_column('END_TIME',time_from_parts(15,0,'END_TIME')).\\\n",
    "with_column('MINUTES',date_trunc('minute','END_TIME'))\n",
    "grouped = grouped.with_column('MINUTES',minute('MINUTES'))\n",
    "data_grouped_minutes = grouped.group_by('RELATIVE_PATH','SPEAKER','SPEAKER_NAME','MINUTES').agg(array_agg('SEGMENT_TEXT').alias('TEXT'),avg('SENTIMENT').alias('SENTIMENT'))\n",
    "\n",
    "st.markdown('''#### Data Grouped to Minutes''')\n",
    "data_grouped_minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df2b58-e1be-4ffd-94ed-30642dd1d85d",
   "metadata": {
    "collapsed": false,
    "name": "smoother"
   },
   "source": [
    "Below is a much smoother output - and a lot easier to read.  We are also able to view these grouped snippets in the visualistion.  Here, we are featuring the Most popular minute of the year, followed by the most negative minute of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb79850-3258-44dc-8552-ae0c126dd812",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "grouped_minutes",
    "resultHeight": 790
   },
   "outputs": [],
   "source": [
    "st.markdown('#### Sentiment Analysis during the duration of the last 3 quarterly earnings calls')\n",
    "col1,col2,col3 = st.columns(3)\n",
    "\n",
    "with col1:\n",
    "\n",
    "    st.markdown('#### Q1')\n",
    "    q1 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q1_FY2025.mp3')\n",
    "    st.line_chart(q1,\n",
    "              y='SENTIMENT',x='MINUTES',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q1.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col2:\n",
    "    q2 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q2_FY2025.mp3')\n",
    "    st.markdown('#### Q2')\n",
    "    st.line_chart(q2,\n",
    "              y='SENTIMENT',x='MINUTES',color = '#29B5E8')\n",
    "    st.metric('Average Sentiment',q2.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "with col3:\n",
    "    \n",
    "    st.markdown('#### Q3')\n",
    "    q3 = data_grouped_minutes.filter(col('RELATIVE_PATH')=='EARNINGS_Q3_FY2025.mp3')\n",
    "    st.line_chart(q3,\n",
    "              y='SENTIMENT',x='MINUTES',color = '#FF9F36')\n",
    "    st.metric('Average Sentiment',q3.agg(avg('SENTIMENT').alias('SENTIMENT')).select(round('SENTIMENT',2)).collect()[0][0])\n",
    "\n",
    "st.markdown(f'''**:bulb: Most positive minute of the year**: \\\n",
    "{data_grouped_minutes.sort(col('SENTIMENT').desc()).limit(1).select(array_to_string(col('TEXT'),lit(''))).collect()[0][0]}''')\n",
    "\n",
    "st.markdown(f'''**:warning: Most negative minute of the year**: \\\n",
    "{data_grouped_minutes.sort(col('SENTIMENT').asc()).limit(1).select(array_to_string(col('TEXT'),lit(''))).collect()[0][0]}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3e259-c75e-41a0-9577-513a6a5af6a5",
   "metadata": {
    "collapsed": false,
    "name": "regexp"
   },
   "source": [
    "Now lets remove the arrays to visualise pure text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46c13e-7e46-46a9-b4ea-1a8f83294f61",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "format_text",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "grouped_text_minute = data_grouped_minutes.with_column(\n",
    "    'TEXT',\n",
    "    regexp_replace(cast(col('TEXT'), StringType()), r'[\\[\\]\"]', '')).sort(col('RELATIVE_PATH'),col('MINUTES')\n",
    ")\n",
    "grouped_text_minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9806be-ee88-4bed-8677-3988b54f1591",
   "metadata": {
    "collapsed": false,
    "name": "speaker_analysis"
   },
   "source": [
    "We can also use the AI_TRANSCRIBE results to analyse by speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5020dc-4c2e-44d8-86a2-5ecdb5dd1fa6",
   "metadata": {
    "language": "python",
    "name": "sentiment_by_speaker"
   },
   "outputs": [],
   "source": [
    "grouped_text_speaker = data_grouped_minutes.group_by('RELATIVE_PATH','SPEAKER_NAME').agg(avg('SENTIMENT').alias('SENTIMENT'),\n",
    "                                                                                   array_agg('TEXT').alias('TEXT'))\n",
    "\n",
    "\n",
    "grouped_text_speaker = grouped_text_speaker.with_column(\n",
    "    'TEXT',\n",
    "    regexp_replace(cast(col('TEXT'), StringType()), r'[\\[\\]\"]', '')).sort(col('RELATIVE_PATH'),col('SPEAKER_NAME')\n",
    ")\n",
    "\n",
    "\n",
    "filtered_call = st.selectbox('Choose Call',grouped_text_speaker.select('RELATIVE_PATH').distinct())\n",
    "grouped_text_speakerf = grouped_text_speaker.filter(col('RELATIVE_PATH')==filtered_call)\n",
    "grouped_text_speakerf\n",
    "st.bar_chart(grouped_text_speakerf, x='SPEAKER_NAME',y='SENTIMENT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2ba53-bbba-463d-84b7-aafea838a2f1",
   "metadata": {
    "collapsed": false,
    "name": "focus_entire_call"
   },
   "source": [
    "### Transcribe without segments\n",
    "\n",
    "We will now use the built in AI_TRANSCRIBE function to transcribe the audio files. We also summarise the call and put a final sentiment score for the entire call.  Have a look at the sentiment call when the entire call is put in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f8c87-f8bb-4a10-a7ab-c08164b1b5c0",
   "metadata": {
    "language": "sql",
    "name": "ai_transcribe"
   },
   "outputs": [],
   "source": [
    "CREATE TABLE IF NOT EXISTS DEFAULT_SCHEMA.AI_TRANSCRIBE_NO_TIME AS \n",
    "\n",
    "SELECT RELATIVE_PATH, TRANSCRIBED:text::text TEXT, TRANSCRIBED:audio_duration DURATION FROM\n",
    "\n",
    "(\n",
    "\n",
    "select RELATIVE_PATH, AI_TRANSCRIBE(TO_FILE('@DOCUMENT_AI.EARNINGS_CALLS', relative_path)) TRANSCRIBED from directory(@DOCUMENT_AI.EARNINGS_CALLS) );\n",
    "\n",
    "SELECT * FROM DEFAULT_SCHEMA.AI_TRANSCRIBE_NO_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84fa76-7177-46f3-9ca5-9013734a06bd",
   "metadata": {
    "language": "python",
    "name": "aggregate_text_per_call"
   },
   "outputs": [],
   "source": [
    "entire_call = session.table('DEFAULT_SCHEMA.AI_TRANSCRIBE_NO_TIME')\n",
    "\n",
    "entire_call = entire_call.with_column('SUMMARY',snowflake_cortex_summarize(col('TEXT')))\n",
    "entire_call = entire_call.with_column('SENTIMENT',call_function('SNOWFLAKE.CORTEX.SENTIMENT',(col('SUMMARY'))))\n",
    "entire_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f000610-a836-4b17-aa9e-c192b48379dc",
   "metadata": {
    "collapsed": false,
    "name": "heading_save_data_in_table",
    "resultHeight": 47
   },
   "source": [
    "#### Save data in a table\n",
    "Finally lets save the results in a table.   Let's examine the text further with text based search functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20573f93-500d-48d8-b4bd-aa7bf3334dbf",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_table",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "grouped_text_minute.write.mode(\"overwrite\").save_as_table(\"DEFAULT_SCHEMA.transcripts_by_minute\")\n",
    "entire_call.write.mode(\"overwrite\").save_as_table(\"DEFAULT_SCHEMA.full_transcripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849dee4e-9d0e-46f0-b747-65330c11f782",
   "metadata": {
    "collapsed": false,
    "name": "head_embeddings"
   },
   "source": [
    "### VECTOR EMBEDDINGS\n",
    "The calls will be chunked and then embedded to make them searchable.\n",
    "\n",
    "An embedding refers to the reduction of high-dimensional data, such as unstructured text, to a representation with fewer dimensions, such as a vector. Modern deep learning techniques can create vector embeddings, which are structured numerical representations, from unstructured data such as text and images, preserving semantic notions of similarity and dissimilarity in the geometry of the vectors they produce.\n",
    "\n",
    "The illustration below is a simplified example of the vector embedding and geometric similarity of natural language text. In practice, neural networks produce embedding vectors with hundreds or even thousands of dimensions, not two as shown here, but the concept is the same. Semantically similar text yields vectors that “point” in the same general direction.\n",
    "\n",
    "![embeddings](https://docs.snowflake.com/en/_images/vector-similarity-vectors-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba5efd-74a0-4c85-9e0c-6b35cf1ce205",
   "metadata": {
    "collapsed": false,
    "name": "head_split_embed"
   },
   "source": [
    "Below uses cortex **split text recursive character** to split as before, and in addition, uses **embed text 1024** to embed the text to 1024 dimensions.\n",
    "\n",
    "As the data is chunked based on number of characters with the addition to an overlap, a new sentiment score is also added to the new chunked table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef656f67-a497-461e-a2a1-054ba09d97e4",
   "metadata": {
    "language": "python",
    "name": "embed_text"
   },
   "outputs": [],
   "source": [
    "entire_call = session.table('DEFAULT_SCHEMA.full_transcripts')\n",
    "#### chunk the calls ####\n",
    "chunked = entire_call.with_column('TEXT',call_function('SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER',col('TEXT'),'none',500,20))\n",
    "chunked = chunked.join_table_function('flatten','TEXT').select('RELATIVE_PATH','SUMMARY',col('VALUE').astype(StringType()).alias('TEXT'))\n",
    "\n",
    "#### apply sentiment per chunk\n",
    "\n",
    "chunked = chunked.with_column('SENTIMENT',call_function('AI_SENTIMENT',col('TEXT'))['categories'][0]['sentiment'].astype(StringType()))\n",
    "chunked = chunked.with_column('SENTIMENT_SCORE',call_function('SNOWFLAKE.CORTEX.SENTIMENT',col('TEXT')))\n",
    "#### embed the calls ###\n",
    "\n",
    "chunked = chunked.with_column('EMBED',call_function('SNOWFLAKE.CORTEX.EMBED_TEXT_1024',lit('snowflake-arctic-embed-l-v2.0'),col('TEXT')))\n",
    "\n",
    "\n",
    "chunked.write.mode(\"overwrite\").save_as_table(\"DEFAULT_SCHEMA.call_embeds\")\n",
    "chunked = session.table('DEFAULT_SCHEMA.call_embeds')\n",
    "chunked.limit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e66aca-74d1-4836-b343-f2aa3a537fdb",
   "metadata": {
    "collapsed": false,
    "name": "head_search"
   },
   "source": [
    "Now you will try and search the call text using the the search box below.  It will compare the embedded search **phrase** with the embeddings of the chunked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104325a-9a70-40a4-aee3-8da9fd48fbf9",
   "metadata": {
    "language": "python",
    "name": "embeds_and_search"
   },
   "outputs": [],
   "source": [
    "call = st.selectbox('Select Earnings Call:',entire_call.select('RELATIVE_PATH').distinct())\n",
    "\n",
    "with st.container(height=900):\n",
    "    st.markdown('### SUMMARY')\n",
    "    chunked.filter(col('RELATIVE_PATH')==call).select('SUMMARY').collect()[0][0]\n",
    "    keyword = st.text_input('Search Text:')\n",
    "    search = chunked.filter(col('RELATIVE_PATH')==call)\n",
    "    \n",
    "    search = search.with_column('embed_search',call_function('SNOWFLAKE.CORTEX.EMBED_TEXT_1024',\n",
    "                                                     lit('snowflake-arctic-embed-l-v2.0'),\n",
    "                                                     lit(keyword)).alias('TOKEN'))\n",
    "\n",
    "    search = search.with_column('score',call_function('VECTOR_COSINE_SIMILARITY',col('EMBED'),col('EMBED_SEARCH')))\n",
    "    st.markdown('### SEARCH RESULTS')\n",
    "    st.table(search.select('TEXT','SCORE','SENTIMENT').sort(col('score').desc()).limit(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0edda-d196-4879-bedf-ee86b5066ed1",
   "metadata": {
    "collapsed": false,
    "name": "search_service"
   },
   "source": [
    "This is the principle of how the search service works.  Cortex search does all the embeddings for the user, this is what you will do in the next section - **Create a Search Service**.  Before we create a search service - lets explore **AI_SENTIMENT** where you can add sentiment categories as apposed to a score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb39fb-883f-4010-a7b1-f3b1124c7c92",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "### Use AI_SENTIMENT to get a human readable sentiment value.\n",
    "\n",
    "AI Sentiment is used to get an actual sentiment in a readable word.  This will either be unknown, positive, negative, neutral or mixed.  Let's apply this type of score to the chunked dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b3f2d-dd20-4958-b026-283c9ca58d7a",
   "metadata": {
    "language": "sql",
    "name": "AI_Sentiment"
   },
   "outputs": [],
   "source": [
    "--CREATE OR REPLACE TABLE DATA_FOR_SEARCH_SERVICE\n",
    "\n",
    "SELECT RELATIVE_PATH, TEXT, SENTIMENT SENTIMENT_SCORE,\n",
    "\n",
    "       SENTIMENT_CATEGORIES:categories[0]:sentiment::TEXT OVERALL_SENTIMENT,\n",
    "       SENTIMENT_CATEGORIES:categories[1]:sentiment::TEXT COST_SENTIMENT,\n",
    "       SENTIMENT_CATEGORIES:categories[2]:sentiment::TEXT INNOVATION_SENTIMENT,\n",
    "       SENTIMENT_CATEGORIES:categories[3]:sentiment::TEXT PRODUCTIVITY_SENTIMENT,\n",
    "       SENTIMENT_CATEGORIES:categories[4]:sentiment::TEXT COMPETITIVENESS_SENTIMENT,\n",
    "       SENTIMENT_CATEGORIES:categories[5]:sentiment::TEXT CONSUMPTION_SENTIMENT\n",
    "\n",
    "from (\n",
    "select * exclude embed,AI_SENTIMENT(TEXT,['Cost','Innovation','productivity','competitiveness','consumption']) SENTIMENT_CATEGORIES from DEFAULT_SCHEMA.call_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85bf243-ba67-4673-99f1-92630ca81ab6",
   "metadata": {
    "collapsed": false,
    "name": "SQL_to_support_analysis"
   },
   "source": [
    "We will now create a sql table to further support sentiment analyse which effectively counts the number of iterations of sentiment category by type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c01d3-b507-4840-9e2d-fa519b92c6fd",
   "metadata": {
    "language": "sql",
    "name": "sentiment_analysis"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE DEFAULT_SCHEMA.SENTIMENT_ANALYSIS AS \n",
    "\n",
    "select \n",
    "\n",
    "RELATIVE_PATH,\n",
    "any_value('POSITIVE') SENTIMENT,\n",
    "COUNT(CASE OVERALL_SENTIMENT WHEN 'positive' then 1 end) OVERALL,\n",
    "\n",
    "COUNT(CASE COST_SENTIMENT WHEN 'positive' then 1 end) COST,\n",
    "COUNT(CASE INNOVATION_SENTIMENT WHEN 'positive' then 1 end) INNOVATION,\n",
    "COUNT(CASE PRODUCTIVITY_SENTIMENT WHEN 'positive' then 1 end) PRODUCTIVITY,\n",
    "COUNT(CASE COMPETITIVENESS_SENTIMENT WHEN 'positive' then 1 end) COMPETITIVENESS,\n",
    "COUNT(CASE CONSUMPTION_SENTIMENT WHEN 'positive' then 1 end) CONSUMPTION,\n",
    "\n",
    "\n",
    "from {{AI_Sentiment}} GROUP BY ALL\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "\n",
    "RELATIVE_PATH,\n",
    "any_value('NEGATIVE') SENTIMENT,\n",
    "COUNT(CASE OVERALL_SENTIMENT WHEN 'negative' then 1 end) OVERALL,\n",
    "\n",
    "COUNT(CASE COST_SENTIMENT WHEN 'negative' then 1 end) COST,\n",
    "COUNT(CASE INNOVATION_SENTIMENT WHEN 'negative' then 1 end) INNOVATION,\n",
    "COUNT(CASE PRODUCTIVITY_SENTIMENT WHEN 'negative' then 1 end) PRODUCTIVITY,\n",
    "COUNT(CASE COMPETITIVENESS_SENTIMENT WHEN 'negative' then 1 end) COMPETITIVENESS,\n",
    "COUNT(CASE CONSUMPTION_SENTIMENT WHEN 'negative' then 1 end) CONSUMPTION,\n",
    "\n",
    "\n",
    "from {{AI_Sentiment}} GROUP BY ALL\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "\n",
    "RELATIVE_PATH,\n",
    "any_value('NEUTRAL') SENTIMENT,\n",
    "COUNT(CASE OVERALL_SENTIMENT WHEN 'neutral' then 1 end) OVERALL,\n",
    "\n",
    "COUNT(CASE COST_SENTIMENT WHEN 'neutral' then 1 end) COST,\n",
    "COUNT(CASE INNOVATION_SENTIMENT WHEN 'neutral' then 1 end) INNOVATION,\n",
    "COUNT(CASE PRODUCTIVITY_SENTIMENT WHEN 'neutral' then 1 end) PRODUCTIVITY,\n",
    "COUNT(CASE COMPETITIVENESS_SENTIMENT WHEN 'neutral' then 1 end) COMPETITIVENESS,\n",
    "COUNT(CASE CONSUMPTION_SENTIMENT WHEN 'neutral' then 1 end) CONSUMPTION,\n",
    "\n",
    "\n",
    "from {{AI_Sentiment}} GROUP BY ALL\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "\n",
    "RELATIVE_PATH,\n",
    "any_value('MIXED') SENTIMENT,\n",
    "COUNT(CASE OVERALL_SENTIMENT WHEN 'mixed' then 1 end) OVERALL,\n",
    "\n",
    "COUNT(CASE COST_SENTIMENT WHEN 'mixed' then 1 end) COST,\n",
    "COUNT(CASE INNOVATION_SENTIMENT WHEN 'mixed' then 1 end) INNOVATION,\n",
    "COUNT(CASE PRODUCTIVITY_SENTIMENT WHEN 'mixed' then 1 end) PRODUCTIVITY,\n",
    "COUNT(CASE COMPETITIVENESS_SENTIMENT WHEN 'mixed' then 1 end) COMPETITIVENESS,\n",
    "COUNT(CASE CONSUMPTION_SENTIMENT WHEN 'mixed' then 1 end) CONSUMPTION,\n",
    "\n",
    "\n",
    "from {{AI_Sentiment}} GROUP BY ALL\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "RELATIVE_PATH,\n",
    "any_value('UNKNOWN') SENTIMENT,\n",
    "COUNT(CASE OVERALL_SENTIMENT WHEN 'unknown' then 1 end) OVERALL,\n",
    "\n",
    "COUNT(CASE COST_SENTIMENT WHEN 'unknown' then 1 end) COST,\n",
    "COUNT(CASE INNOVATION_SENTIMENT WHEN 'unknown' then 1 end) INNOVATION,\n",
    "COUNT(CASE PRODUCTIVITY_SENTIMENT WHEN 'unknown' then 1 end) PRODUCTIVITY,\n",
    "COUNT(CASE COMPETITIVENESS_SENTIMENT WHEN 'unknown' then 1 end) COMPETITIVENESS,\n",
    "COUNT(CASE CONSUMPTION_SENTIMENT WHEN 'unknown' then 1 end) CONSUMPTION,\n",
    "\n",
    "\n",
    "from {{AI_Sentiment}} GROUP BY ALL;\n",
    "\n",
    "SELECT * FROM DEFAULT_SCHEMA.SENTIMENT_ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604291bd-8f93-4798-a5cd-e7818482177c",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "### View the data graphically using Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94440c95-486e-4000-90ae-246df76ae984",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "view_all_sentiments"
   },
   "outputs": [],
   "source": [
    "selected_relative_path = st.selectbox('Choose Call',sentiment_analysis.to_df().select('RELATIVE_PATH').distinct())\n",
    "sentiment_analysis_1 = session.table('DEFAULT_SCHEMA.SENTIMENT_ANALYSIS').filter(col('RELATIVE_PATH') == selected_relative_path)\n",
    "\n",
    "col1,col2,col3,col4,col5 = st.columns(5)\n",
    "\n",
    "with col1:\n",
    "    st.markdown('COST')\n",
    "    st.bar_chart(sentiment_analysis_1, x='SENTIMENT',y='COST',color='#FF9F36',y_label='',x_label='', horizontal=True\n",
    "                )\n",
    "with col2:\n",
    "    st.markdown('INNOVATION')\n",
    "    st.bar_chart(sentiment_analysis_1, x='SENTIMENT',y='INNOVATION',color='#FF9F36',y_label='',x_label='', horizontal=True)\n",
    "\n",
    "with col3:\n",
    "    st.markdown('PRODUCTIVITY')\n",
    "    st.bar_chart(sentiment_analysis_1, x='SENTIMENT',y='PRODUCTIVITY',color='#FF9F36',y_label='',x_label='', horizontal=True)\n",
    "with col4:\n",
    "    st.markdown('COMPETITIVENESS')\n",
    "    st.bar_chart(sentiment_analysis_1, x='SENTIMENT',y='COMPETITIVENESS',color='#FF9F36',y_label='',x_label='', horizontal=True)\n",
    "with col5:\n",
    "    st.markdown('CONSUMPTION')\n",
    "    st.bar_chart(sentiment_analysis_1, x='SENTIMENT',y='CONSUMPTION',color='#FF9F36',y_label='',x_label='', horizontal=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "",
   "authorId": "7518827724888",
   "authorName": "USER",
   "lastEditTime": 1761697480167,
   "notebookId": "rxyr4b5q2wfqie4biawp",
   "sessionId": "4f076495-d831-41d8-9c34-7f7d9b02b946"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
